{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[],"dockerImageVersionId":31192,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"##### Copyright 2025 Google LLC.","metadata":{}},{"cell_type":"code","source":"# @title Licensed under the Apache License, Version 2.0 (the \"License\");\n# you may not use this file except in compliance with the License.\n# You may obtain a copy of the License at\n#\n# https://www.apache.org/licenses/LICENSE-2.0\n#\n# Unless required by applicable law or agreed to in writing, software\n# distributed under the License is distributed on an \"AS IS\" BASIS,\n# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n# See the License for the specific language governing permissions and\n# limitations under the License.","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"# üß† Memory Management - Part 2 - Memory\n\n**Welcome to Day 3 of the Kaggle 5-day Agents course!**\n\nIn the previous notebook, you learned how **Sessions** manage conversation threads. Now you'll add **Memory** - a searchable, long-term knowledge store that persists across multiple conversations.\n\n### What is Memory ‚ùì\n\nMemory is a service that provides long-term knowledge storage for your agents. The key distinction:\n\n> **Session = Short-term memory** (single conversation)\n> \n> **Memory = Long-term knowledge** (across multiple conversations)\n\nThink of it in software engineering terms: **Session** is like application state (temporary), while **Memory** is like a database (persistent).","metadata":{}},{"cell_type":"markdown","source":"### ü§î Why Memory?\n\nMemory provides capabilities that Sessions alone cannot:\n\n| Capability | What It Means | Example |\n|------------|---------------|---------|\n| **Cross-Conversation Recall** | Access information from any past conversation | \"What preferences has this user mentioned across all chats?\" |\n| **Intelligent Extraction** | LLM-powered consolidation extracts key facts | Stores \"allergic to peanuts\" instead of 50 raw messages |\n| **Semantic Search** | Meaning-based retrieval, not just keyword matching | Query \"preferred hue\" matches \"favorite color is blue\" |\n| **Persistent Storage** | Survives application restarts | Build knowledge that grows over time |\n\n**Example:** Imagine talking to a personal assistant:\n- üó£Ô∏è **Session**: They remember what you said 10 minutes ago in THIS conversation\n- üß† **Memory**: They remember your preferences from conversations LAST WEEK","metadata":{}},{"cell_type":"markdown","source":"### üéØ What you'll learn:\n\n- ‚úÖ Initialize MemoryService and integrate with your agent\n- ‚úÖ Transfer session data to memory storage\n- ‚úÖ Search and retrieve memories\n- ‚úÖ Automate memory storage and retrieval\n- ‚úÖ Understand memory consolidation (conceptual overview)\n\n#### üìù Implementation Note\n\n> This notebook uses `InMemoryMemoryService` for learning - it performs keyword matching and doesn't persist data. \n>\n> For production applications, use **Vertex AI Memory Bank** (covered in Day 5), which provides LLM-powered consolidation and semantic search with persistent cloud storage.","metadata":{}},{"cell_type":"markdown","source":"## ‚ÄºÔ∏è Please Read\n\n\n> ‚ùå **‚ÑπÔ∏è Note: No submission required!**\n> This notebook is for your hands-on practice and learning only. You **do not** need to submit it anywhere to complete the course.\n\n> ‚è∏Ô∏è **Note:**  When you first start the notebook via running a cell you might see a banner in the notebook header that reads **\"Waiting for the next available notebook\"**. The queue should drop rapidly; however, during peak bursts you might have to wait a few minutes.\n\n> ‚ùå **Note:** Avoid using the **Run all** cells command as this can trigger a QPM limit resulting in 429 errors when calling the backing model. Suggested flow is to run each cell in order - one at a time. [See FAQ on 429 errors for more information.](https://www.kaggle.com/code/kaggle5daysofai/day-0-troubleshooting-and-faqs)\n\n**For help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.**","metadata":{}},{"cell_type":"markdown","source":"---","metadata":{}},{"cell_type":"markdown","source":"## üìñ Get started with Kaggle Notebooks\n\nIf this is your first time using Kaggle Notebooks, welcome! You can learn more about using Kaggle Notebooks [in the documentation](https://www.kaggle.com/docs/notebooks).\n\nHere's how to get started:\n\n**1. Verify Your Account (Required)**\n\nTo use the Kaggle Notebooks in this course, you'll need to verify your account with a phone number.\n\nYou can do this in your [Kaggle settings](https://www.kaggle.com/settings).\n\n**2. Make Your Own Copy**\n\nTo run any code in this notebook, you first need your own editable copy.\n\nClick the `Copy and Edit` button in the top-right corner.\n\n![Copy and Edit button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_1.png)\n\nThis creates a private copy of the notebook just for you.\n\n**3. Run Code Cells**\n\nOnce you have your copy, you can run code.\n\nClick the ‚ñ∂Ô∏è Run button next to any code cell to execute it.\n\n![Run cell button](https://storage.googleapis.com/kaggle-media/Images/5gdai_sc_2.png)\n\nRun the cells in order from top to bottom.\n\n**4. If You Get Stuck**\n\nTo restart: Select `Factory reset` from the `Run` menu.\n\nFor help: Ask questions on the [Kaggle Discord](https://discord.com/invite/kaggle) server.","metadata":{}},{"cell_type":"markdown","source":"---\n## ‚öôÔ∏è Section 1: Setup\n\n### 1.1: Install dependencies\n\nThe Kaggle Notebooks environment includes a pre-installed version of the [google-adk](https://google.github.io/adk-docs/) library for Python and its required dependencies, so you don't need to install additional packages in this notebook.\n\nTo install and use ADK in your own Python development environment outside of this course, you can do so by running:\n\n```\npip install google-adk\n```","metadata":{}},{"cell_type":"markdown","source":"### 1.2: Configure your Gemini API Key\n\nThis notebook uses the [Gemini API](https://ai.google.dev/gemini-api/docs), which requires authentication.\n\n**1. Get your API key**\n\nIf you don't have one already, create an [API key in Google AI Studio](https://aistudio.google.com/app/api-keys).\n\n**2. Add the key to Kaggle Secrets**\n\nNext, you will need to add your API key to your Kaggle Notebook as a Kaggle User Secret.\n\n1. In the top menu bar of the notebook editor, select `Add-ons` then `Secrets`.\n2. Create a new secret with the label `GOOGLE_API_KEY`.\n3. Paste your API key into the \"Value\" field and click \"Save\".\n4. Ensure that the checkbox next to `GOOGLE_API_KEY` is selected so that the secret is attached to the notebook.\n\n**3. Authenticate in the notebook**\n\nRun the cell below to complete authentication.","metadata":{}},{"cell_type":"code","source":"import os\nfrom kaggle_secrets import UserSecretsClient\n\ntry:\n    GOOGLE_API_KEY = UserSecretsClient().get_secret(\"GOOGLE_API_KEY\")\n    os.environ[\"GOOGLE_API_KEY\"] = GOOGLE_API_KEY\n    print(\"‚úÖ Gemini API key setup complete.\")\nexcept Exception as e:\n    print(\n        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n    )","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T02:00:04.562725Z","iopub.execute_input":"2026-01-02T02:00:04.563022Z","iopub.status.idle":"2026-01-02T02:00:04.619492Z","shell.execute_reply.started":"2026-01-02T02:00:04.562997Z","shell.execute_reply":"2026-01-02T02:00:04.618742Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Gemini API key setup complete.\n","output_type":"stream"}],"execution_count":1},{"cell_type":"markdown","source":"### 1.3: Import ADK components\n\nNow, import the specific components you'll need from the Agent Development Kit and the Generative AI library. This keeps your code organized and ensures we have access to the necessary building blocks.","metadata":{}},{"cell_type":"code","source":"from google.adk.agents import LlmAgent\nfrom google.adk.models.google_llm import Gemini\nfrom google.adk.runners import Runner\nfrom google.adk.sessions import InMemorySessionService\nfrom google.adk.memory import InMemoryMemoryService\nfrom google.adk.tools import load_memory, preload_memory\nfrom google.genai import types\n\nprint(\"‚úÖ ADK components imported successfully.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T02:00:06.207828Z","iopub.execute_input":"2026-01-02T02:00:06.208578Z","iopub.status.idle":"2026-01-02T02:00:26.127514Z","shell.execute_reply.started":"2026-01-02T02:00:06.208542Z","shell.execute_reply":"2026-01-02T02:00:26.126690Z"}},"outputs":[{"name":"stdout","text":"‚úÖ ADK components imported successfully.\n","output_type":"stream"}],"execution_count":2},{"cell_type":"markdown","source":"### 1.4: Helper functions\n\nThis helper function manages a complete conversation session, handling session creation/retrieval, query processing, and response streaming.","metadata":{}},{"cell_type":"code","source":"async def run_session(\n    runner_instance: Runner, user_queries: list[str] | str, session_id: str = \"default\"\n):\n    \"\"\"Helper function to run queries in a session and display responses.\"\"\"\n    print(f\"\\n### Session: {session_id}\")\n\n    # Create or retrieve session\n    try:\n        session = await session_service.create_session(\n            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n        )\n    except:\n        session = await session_service.get_session(\n            app_name=APP_NAME, user_id=USER_ID, session_id=session_id\n        )\n\n    # Convert single query to list\n    if isinstance(user_queries, str):\n        user_queries = [user_queries]\n\n    # Process each query\n    for query in user_queries:\n        print(f\"\\nUser > {query}\")\n        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n\n        # Stream agent response\n        async for event in runner_instance.run_async(\n            user_id=USER_ID, session_id=session.id, new_message=query_content\n        ):\n            if event.is_final_response() and event.content and event.content.parts:\n                text = event.content.parts[0].text\n                if text and text != \"None\":\n                    print(f\"Model: > {text}\")\n\n\nprint(\"‚úÖ Helper functions defined.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T02:00:26.128659Z","iopub.execute_input":"2026-01-02T02:00:26.129129Z","iopub.status.idle":"2026-01-02T02:00:26.136832Z","shell.execute_reply.started":"2026-01-02T02:00:26.129107Z","shell.execute_reply":"2026-01-02T02:00:26.135999Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Helper functions defined.\n","output_type":"stream"}],"execution_count":3},{"cell_type":"markdown","source":"### 1.5: Configure Retry Options\n\nWhen working with LLMs, you may encounter transient errors like rate limits or temporary service unavailability. Retry options automatically handle these failures by retrying the request with exponential backoff.","metadata":{}},{"cell_type":"code","source":"retry_config = types.HttpRetryOptions(\n    attempts=5,  # Maximum retry attempts\n    exp_base=7,  # Delay multiplier\n    initial_delay=1,\n    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T02:00:26.137522Z","iopub.execute_input":"2026-01-02T02:00:26.137795Z","iopub.status.idle":"2026-01-02T02:00:26.155881Z","shell.execute_reply.started":"2026-01-02T02:00:26.137769Z","shell.execute_reply":"2026-01-02T02:00:26.155117Z"}},"outputs":[],"execution_count":4},{"cell_type":"markdown","source":"<h1 style=\"color:#FF4FA3; font-weight:800; margin:0;\">\n  Xing's Summary <span style=\"font-weight:500;\">\n      (so that no need to go into verbose sections below)</span>\n</h1>\n\n## Core components:\n1. session_service -> state within a conversation (short-term memory)\n2. memory_service -> state across conversations (long-term memory)\n3. agent -> decision-maker: given context, decides next action\n4. runner -> chief of staff: drives the loop, wires 1/2/3 together, executes decisions\n\n## How agent and runner interact:\n- Runner: \"Here's user input + context. What do you want to do?\"\n- Agent:  \"Call tool X with args Y\"\n- Runner: [executes tool X, gets result]\n- Runner: \"Tool returned Z. Now what?\"\n- Agent:  \"Respond to user with this message\"\n- Runner: [sends response, updates session/memory]\n\n## More precisely:\n1. session_service: per-conversation working state (messages, scratch, cached tool results)\n2. memory_service: curated cross-conversation memories (selective, policy-gated)\n3. agent: policy/brain; given state, emits next action(s) (respond, ask, tool call, plan)\n4. runner: orchestrator; enforces budgets/policy, executes actions/tools, updates session, proposes/commits memory\n   \n<h2 style=\"color:red; font-weight:800; margin:0;\">\nIssue<span style=\"font-weight:500;\"></span>\n</h2>\n\napp_name + user_id + session_id form the composite key for session/memory lookup. The code hides this by scattering them as globals and not surfacing them in function signatures","metadata":{"execution":{"iopub.status.busy":"2026-01-01T21:11:25.074642Z","iopub.execute_input":"2026-01-01T21:11:25.074990Z","iopub.status.idle":"2026-01-01T21:11:25.079018Z","shell.execute_reply.started":"2026-01-01T21:11:25.074964Z","shell.execute_reply":"2026-01-01T21:11:25.078224Z"}}},{"cell_type":"code","source":"# tools \n# ------------------------------------------------------------------\nasync def auto_save_to_memory(callback_context):\n    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n    await callback_context._invocation_context.memory_service.add_session_to_memory(\n        callback_context._invocation_context.session\n    )\n\n\nprint(\"‚úÖ Tool - callback created.\")\n\n\n# key components\n# ------------------------------------------------------------------\nUSER_ID = 'p_li_mom'\nAPP_NAME = 'p_li'\n\n# 1. Session Service\nsession_service = InMemorySessionService()  # Handles conversations\n\n# 2. Memory Service\nmemory_service = (InMemoryMemoryService()) \n\n# 3. Agent \nuser_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"MemoryDemoAgent\",\n    instruction=\"Answer user questions in simple words. You may need to use the load_memory tool first to check for relevant context about the user.\",\n    tools = [load_memory], # optional, and adding this allows memory retrieval,\n    after_agent_callback=auto_save_to_memory,  # Optional, and adding this allows for auto memory saving after each call to agent\n    \n)\n\n# 4. Runner\nrunner = Runner(\n    agent=user_agent,\n    app_name=APP_NAME,\n    session_service=session_service,\n    memory_service=memory_service, \n)\n\nprint(\"‚úÖ Core components created.\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T02:04:39.724786Z","iopub.execute_input":"2026-01-02T02:04:39.725781Z","iopub.status.idle":"2026-01-02T02:04:39.732733Z","shell.execute_reply.started":"2026-01-02T02:04:39.725750Z","shell.execute_reply":"2026-01-02T02:04:39.731944Z"}},"outputs":[{"name":"stdout","text":"‚úÖ Tool - callback created.\n‚úÖ Core components created.\n","output_type":"stream"}],"execution_count":9},{"cell_type":"code","source":"await run_session(\n    runner,\n    \"my dog is p li, it is a labradoodle, it is 4\",\n    \"p_li_session_1\",\n)\n\n# manually load session to memory\n# session = await session_service.get_session(app_name = APP_NAME, user_id = USER_ID, session_id = \"p_li_session_1\")\n# await memory_service.add_session_to_memory(session)\n\nawait run_session(\n    runner,\n    \"tell me more about my dog\",\n    \"p_li_session_2\",  # Different session ID - proves memory works across sessions!\n)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T02:05:53.660194Z","iopub.execute_input":"2026-01-02T02:05:53.660749Z","iopub.status.idle":"2026-01-02T02:05:55.159418Z","shell.execute_reply.started":"2026-01-02T02:05:53.660721Z","shell.execute_reply":"2026-01-02T02:05:55.158623Z"}},"outputs":[{"name":"stdout","text":"\n### Session: p_li_session_1\n\nUser > my dog is p li, it is a labradoodle, it is 4\nModel: > I see. So your dog is a 4-year-old Labradoodle. Is there anything you'd like to know about Labradoodles or anything else I can help you with?\n\n\n### Session: p_li_session_2\n\nUser > tell me more about my dog\n","output_type":"stream"},{"name":"stderr","text":"WARNING:google_genai.types:Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n","output_type":"stream"},{"name":"stdout","text":"Model: > I see that your dog is a 4-year-old Labradoodle. Labradoodles are known for being friendly and intelligent.\n","output_type":"stream"}],"execution_count":12},{"cell_type":"code","source":"# more detailed api usage to save and search memory\nsearch_response = await memory_service.search_memory(\n    app_name=APP_NAME, user_id=USER_ID, query=\"dog\"\n)\n\nprint(\"üîç Search Results:\")\nprint(f\"  Found {len(search_response.memories)} relevant memories\")\nprint()\n\nfor memory in search_response.memories:\n    if memory.content and memory.content.parts:\n        text = memory.content.parts[0].text[:80]\n        print(f\"  [{memory.author}]: {text}...\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2026-01-02T02:06:01.793861Z","iopub.execute_input":"2026-01-02T02:06:01.794175Z","iopub.status.idle":"2026-01-02T02:06:01.800807Z","shell.execute_reply.started":"2026-01-02T02:06:01.794153Z","shell.execute_reply":"2026-01-02T02:06:01.799631Z"}},"outputs":[{"name":"stdout","text":"üîç Search Results:\n  Found 8 relevant memories\n\n  [user]: my dog is p li, it is a labradoodle...\n  [MemoryDemoAgent]: That's great! Labradoodles are known for being friendly and intelligent. What do...\n  [user]: my dog is p li, it is a labradoodle, it is 4...\n  [MemoryDemoAgent]: I see. So your dog is a 4-year-old Labradoodle. Is there anything you'd like to ...\n  [user]: tell me more about my dog...\n  [MemoryDemoAgent]: Your dog is a P. Li, which is a Labradoodle....\n  [user]: tell me more about my dog...\n  [MemoryDemoAgent]: I see that your dog is a 4-year-old Labradoodle. Labradoodles are known for bein...\n","output_type":"stream"}],"execution_count":13},{"cell_type":"markdown","source":"---\n## ü§ì Section 2: Memory Workflow\n\nFrom the Introduction section, you now know why we need Memory. In order to integrate Memory into your Agents, there are **three high-level steps.**\n\n**Three-step integration process:**\n\n1. **Initialize** ‚Üí Create a `MemoryService` and provide it to your agent via the `Runner`\n2. **Ingest** ‚Üí Transfer session data to memory using `add_session_to_memory()`\n3. **Retrieve** ‚Üí Search stored memories using `search_memory()`\n\nLet's explore each step in the following sections.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/memory-workflow.png\" width=\"1400\" alt=\"Memory workflow\">","metadata":{}},{"cell_type":"markdown","source":"---\n## üß† Section 3: Initialize MemoryService","metadata":{}},{"cell_type":"markdown","source":"### 3.1 Initialize Memory\n\nADK provides multiple `MemoryService` implementations through the `BaseMemoryService` interface:\n\n- **`InMemoryMemoryService`** - Built-in service for prototyping and testing (keyword matching, no persistence)\n- **`VertexAiMemoryBankService`** - Managed cloud service with LLM-powered consolidation and semantic search\n- **Custom implementations** - You can build your own using databases, though managed services are recommended\n\nFor this notebook, we'll use `InMemoryMemoryService` to learn the core mechanics. The same methods work identically with production-ready services like Vertex AI Memory Bank.","metadata":{}},{"cell_type":"code","source":"memory_service = (\n    InMemoryMemoryService()\n)  # ADK's built-in Memory Service for development and testing","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 3.2 Add Memory to Agent\n\nNext, create a simple agent to answer user queries.","metadata":{}},{"cell_type":"code","source":"# Define constants used throughout the notebook\nAPP_NAME = \"MemoryDemoApp\"\nUSER_ID = \"demo_user\"\n\n# Create agent\nuser_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"MemoryDemoAgent\",\n    instruction=\"Answer user questions in simple words.\",\n)\n\nprint(\"‚úÖ Agent created\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **Create Runner**\n\nNow provide both Session and Memory services to the `Runner`.\n\n**Key configuration:**\n\nThe `Runner` requires both services to enable memory functionality:\n- **`session_service`** ‚Üí Manages conversation threads and events\n- **`memory_service`** ‚Üí Provides long-term knowledge storage\n\nBoth services work together: Sessions capture conversations, Memory stores knowledge for retrieval across sessions.","metadata":{}},{"cell_type":"code","source":"# Create Session Service\nsession_service = InMemorySessionService()  # Handles conversations\n\n# Create runner with BOTH services\nrunner = Runner(\n    agent=user_agent,\n    app_name=\"MemoryDemoApp\",\n    session_service=session_service,\n    memory_service=memory_service,  # Memory service is now available!\n)\n\nprint(\"‚úÖ Agent and Runner created with memory support!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### ‚ÄºÔ∏è Important\n\n**üí° Configuration vs. Usage:** Adding `memory_service` to the `Runner` makes memory *available* to your agent, but doesn't automatically use it. You must explicitly:\n1. **Ingest data** using `add_session_to_memory()` \n2. **Enable retrieval** by giving your agent memory tools (`load_memory` or `preload_memory`)\n\nLet's learn these steps next!","metadata":{}},{"cell_type":"markdown","source":"### 3.3 MemoryService Implementation Options\n\n**This notebook: `InMemoryMemoryService`**\n- Stores raw conversation events without consolidation\n- Keyword-based search (simple word matching)\n- In-memory storage (resets on restart)\n- Ideal for learning and local development\n\n**Production: `VertexAiMemoryBankService` (You'll learn this on Day 5)**\n- LLM-powered extraction of key facts\n- Semantic search (meaning-based retrieval)\n- Persistent cloud storage\n- Integrates external knowledge sources\n\n**üí° API Consistency:** Both implementations use identical methods (`add_session_to_memory()`, `search_memory()`). The workflow you learn here applies to all memory services!","metadata":{}},{"cell_type":"markdown","source":"---\n## üíæ Section 4: Ingest Session Data into Memory","metadata":{}},{"cell_type":"markdown","source":"**Why should you transfer Session data to Memory?**\n\nNow that memory is initialized, you need to populate it with knowledge. When you initialize a MemoryService, it starts completely empty. All your conversations are stored in Sessions, which contain raw events including every message, tool call, and metadata. To make this information available for long-term recall, you explicitly transfer it to memory using `add_session_to_memory()`.\n\nHere's where managed memory services like Vertex AI Memory Bank shine. **During transfer, they perform intelligent consolidation - extracting key facts while discarding conversational noise.** The `InMemoryMemoryService` we're using stores everything without consolidation, which is sufficient for learning the mechanics.","metadata":{}},{"cell_type":"markdown","source":"Before we can transfer anything, we need data. Let's have a conversation with our agent to populate the session. This conversation will be stored in the SessionService just like you learned in the previous notebook.","metadata":{}},{"cell_type":"code","source":"# User tells agent about their favorite color\nawait run_session(\n    runner,\n    \"My favorite color is blue-green. Can you write a Haiku about it?\",\n    \"conversation-01\",  # Session ID\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Let's verify the conversation was captured in the session. You should see the session events containing both the user's prompt and the model's response.","metadata":{}},{"cell_type":"code","source":"session = await session_service.get_session(\n    app_name=APP_NAME, user_id=USER_ID, session_id=\"conversation-01\"\n)\n\n# Let's see what's in the session\nprint(\"üìù Session contains:\")\nfor event in session.events:\n    text = (\n        event.content.parts[0].text[:60]\n        if event.content and event.content.parts\n        else \"(empty)\"\n    )\n    print(f\"  {event.content.role}: {text}...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Perfect! The session contains our conversation. Now we're ready to transfer it to memory. Call `add_session_to_memory()` and pass the session object. This ingests the conversation into the memory store, making it available for future searches.","metadata":{}},{"cell_type":"code","source":"# This is the key method!\nawait memory_service.add_session_to_memory(session)\n\nprint(\"‚úÖ Session added to memory!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"---\n## üîé Section 5: Enable Memory Retrieval in Your Agent\n\nYou've successfully transferred session data to memory, but there's one crucial step remaining. **Agents can't directly access the MemoryService - they need tools to search it.** \n\nThis is by design: it gives you control over when and how memory is retrieved.","metadata":{}},{"cell_type":"markdown","source":"### 5.1 Memory Retrieval in ADK\n\nADK provides two built-in tools for memory retrieval:\n\n**`load_memory` (Reactive)**\n- Agent decides when to search memory\n- Only retrieves when the agent thinks it's needed\n- More efficient (saves tokens)\n- Risk: Agent might forget to search\n\n**`preload_memory` (Proactive)**\n- Automatically searches before every turn\n- Memory always available to the agent\n- Guaranteed context, but less efficient\n- Searches even when not needed\n\nThink of it like studying for an exam: `load_memory` is looking things up only when you need them, while `preload_memory` is reading all your notes before answering each question.","metadata":{}},{"cell_type":"markdown","source":"### 5.2 Add Load Memory Tool to Agent\n\nLet's start by implementing the reactive pattern. We'll recreate the agent from Section 3, this time adding the `load_memory` tool to its toolkit. Since this is a built-in ADK tool, you simply include it in the tools array without any custom implementation.","metadata":{}},{"cell_type":"code","source":"# Create agent\nuser_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"MemoryDemoAgent\",\n    instruction=\"Answer user questions in simple words. Use load_memory tool if you need to recall past conversations.\",\n    tools=[\n        load_memory\n    ],  # Agent now has access to Memory and can search it whenever it decides to!\n)\n\nprint(\"‚úÖ Agent with load_memory tool created.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.3 Update the Runner and Test\n\nLet's now update the Runner to use our new `user_agent` that has the `load_memory` tool. And we'll ask the Agent about the favorite color which we had stored previously in another session.\n\n**üëâ Since sessions don't share conversation history, the only way the agent can answer correctly is by using the `load_memory` tool** to retrieve the information from long-term memory that we manually stored.","metadata":{}},{"cell_type":"code","source":"# Create a new runner with the updated agent\nrunner = Runner(\n    agent=user_agent,\n    app_name=APP_NAME,\n    session_service=session_service,\n    memory_service=memory_service,\n)\n\nawait run_session(runner, \"What is my favorite color?\", \"color-test\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 5.4 Complete Manual Workflow Test\n\nLet's see the complete workflow in action. We'll have a conversation about a birthday, manually save it to memory, then test retrieval in a new session. This demonstrates the full cycle: **ingest ‚Üí store ‚Üí retrieve**.","metadata":{}},{"cell_type":"code","source":"await run_session(runner, \"My birthday is on March 15th.\", \"birthday-session-01\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Now manually save this session to memory. This is the crucial step that transfers the conversation from short-term session storage to long-term memory storage.","metadata":{}},{"cell_type":"code","source":"# Manually save the session to memory\nbirthday_session = await session_service.get_session(\n    app_name=APP_NAME, user_id=USER_ID, session_id=\"birthday-session-01\"\n)\n\nawait memory_service.add_session_to_memory(birthday_session)\n\nprint(\"‚úÖ Birthday session saved to memory!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"Here's the crucial test: we'll start a completely new session with a different session ID and ask the agent to recall the birthday.","metadata":{}},{"cell_type":"code","source":"# Test retrieval in a NEW session\nawait run_session(\n    runner, \"When is my birthday?\", \"birthday-session-02\"  # Different session ID\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**What happens:**\n\n1. Agent receives: \"When is my birthday?\"\n2. Agent recognizes: This requires past conversation context\n3. Agent calls: `load_memory(\"birthday\")`\n4. Memory returns: Previous conversation containing \"March 15th\"\n5. Agent responds: \"Your birthday is on March 15th\"\n\nThe memory retrieval worked even though this is a completely different session!","metadata":{}},{"cell_type":"markdown","source":"#### üöÄ Your Turn: Experiment with Both Patterns\n\nTry swapping `load_memory` with `preload_memory` by changing the tools array to `tools=[preload_memory]`.\n\n**What changes:**\n- `load_memory` (reactive): Agent decides when to search\n- `preload_memory` (proactive): Automatically loads memory before every turn\n\n**Test it:**\n1. Ask \"What is my favorite color?\" in a new session\n2. Ask \"Tell me a joke\" - notice that `preload_memory` still searches memory even though it's unnecessary\n3. Which pattern is better for different use cases?","metadata":{}},{"cell_type":"markdown","source":"### 5.5 Manual Memory Search\n\nBeyond agent tools, you can also search memories directly in your code. This is useful for:\n- Debugging memory contents\n- Building analytics dashboards  \n- Creating custom memory management UIs\n\nThe `search_memory()` method takes a text query and returns a `SearchMemoryResponse` with matching memories.","metadata":{}},{"cell_type":"code","source":"# Search for color preferences\nsearch_response = await memory_service.search_memory(\n    app_name=APP_NAME, user_id=USER_ID, query=\"What is the user's favorite color?\"\n)\n\nprint(\"üîç Search Results:\")\nprint(f\"  Found {len(search_response.memories)} relevant memories\")\nprint()\n\nfor memory in search_response.memories:\n    if memory.content and memory.content.parts:\n        text = memory.content.parts[0].text[:80]\n        print(f\"  [{memory.author}]: {text}...\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"#### **üöÄ Your Turn: Test Different Queries**\n\nTry these searches to understand how keyword matching works with `InMemoryMemoryService`:\n\n1. **\"what color does the user like\"**\n2. **\"haiku\"**\n3. **\"age\"**\n4. **\"preferred hue\"**\n\nNotice which queries return results and which don't. What pattern do you observe?\n\n**üí° Key Insight:** Memory search is grounded in reality - agents can't hallucinate memories that don't exist.","metadata":{}},{"cell_type":"markdown","source":"### 5.6 How Search Works\n\n**InMemoryMemoryService (this notebook):**\n- **Method:** Keyword matching\n- **Example:** \"favorite color\" matches because those exact words exist\n- **Limitation:** \"preferred hue\" won't match\n\n**VertexAiMemoryBankService (Day 5):**\n- **Method:** Semantic search via embeddings\n- **Example:** \"preferred hue\" WILL match \"favorite color\"\n- **Advantage:** Understands meaning, not just keywords\n\nYou'll explore semantic search in Day 5!","metadata":{}},{"cell_type":"markdown","source":"---\n## ü§ñ Section 6: Automating Memory Storage","metadata":{}},{"cell_type":"markdown","source":"So far, we've **manually** called `add_session_to_memory()` to transfer data to long-term storage. Production systems need this to happen **automatically**.","metadata":{}},{"cell_type":"markdown","source":"### 6.1 Callbacks\n\nADK's callback system lets you hook into key execution moments. Callbacks are **Python functions** you define and attach to agents - ADK automatically calls them at specific stages, acting like checkpoints during the agent's execution flow.\n\n**Think of callbacks as event listeners in your agent's lifecycle.** When an agent processes a request, it goes through multiple stages: receiving the input, calling the LLM, invoking tools, and generating the response. Callbacks let you insert custom logic at each of these stages without modifying the core agent code.\n\n**Available callback types:**\n\n- `before_agent_callback` ‚Üí Runs before agent starts processing a request\n- `after_agent_callback` ‚Üí Runs after agent completes its turn  \n- `before_tool_callback` / `after_tool_callback` ‚Üí Around tool invocations\n- `before_model_callback` / `after_model_callback` ‚Üí Around LLM calls\n- `on_model_error_callback` ‚Üí When errors occur\n\n**Common use cases:**\n\n- Logging and observability (track what the agent does)\n- Automatic data persistence (like saving to memory)\n- Custom validation or filtering\n- Performance monitoring\n\n**üìö Learn More:** [ADK Callbacks Documentation](https://google.github.io/adk-docs/agents/callbacks/)","metadata":{}},{"cell_type":"markdown","source":"![image.png](https://storage.googleapis.com/github-repo/kaggle-5days-ai/day4/types_of_callbacks.png)","metadata":{}},{"cell_type":"markdown","source":"### 6.2 Automatic Memory Storage with Callbacks\n\nFor automatic memory storage, we'll use `after_agent_callback`. This function triggers every time the agent finishes a turn, then calls `add_session_to_memory()` to persist the conversation automatically.\n\nBut here's the challenge: how does our callback function actually access the memory service and current session? That's where `callback_context` comes in.\n\nWhen you define a callback function, ADK automatically passes a special parameter called `callback_context` to it. The `callback_context` provides access to the Memory Service and other runtime components.\n\n**How we'll use it:** In our callback, we'll access the memory service and current session to automatically save conversation data after each turn.\n\n**üí° Important:** You don't create this context - ADK creates it and passes it to your callback automatically when the callback runs.","metadata":{}},{"cell_type":"code","source":"async def auto_save_to_memory(callback_context):\n    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n    await callback_context._invocation_context.memory_service.add_session_to_memory(\n        callback_context._invocation_context.session\n    )\n\n\nprint(\"‚úÖ Callback created.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"### 6.3 Create an Agent: Callback and PreLoad Memory Tool\n\nNow create an agent that combines:\n- **Automatic storage:** `after_agent_callback` saves conversations\n- **Automatic retrieval:** `preload_memory` loads memories\n\nThis creates a fully automated memory system with zero manual intervention.","metadata":{}},{"cell_type":"code","source":"# Agent with automatic memory saving\nauto_memory_agent = LlmAgent(\n    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n    name=\"AutoMemoryAgent\",\n    instruction=\"Answer user questions.\",\n    tools=[preload_memory],\n    after_agent_callback=auto_save_to_memory,  # Saves after each turn!\n)\n\nprint(\"‚úÖ Agent created with automatic memory saving!\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**What happens automatically:**\n\n- After every agent response ‚Üí callback triggers\n- Session data ‚Üí transferred to memory\n- No manual `add_session_to_memory()` calls needed\n\nThe framework handles everything!","metadata":{}},{"cell_type":"markdown","source":"### 6.4 Create a Runner and Test The Agent\n\nTime to test! Create a Runner with the auto-memory agent, connecting the session and memory services.","metadata":{}},{"cell_type":"code","source":"# Create a runner for the auto-save agent\n# This connects our automated agent to the session and memory services\nauto_runner = Runner(\n    agent=auto_memory_agent,  # Use the agent with callback + preload_memory\n    app_name=APP_NAME,\n    session_service=session_service,  # Same services from Section 3\n    memory_service=memory_service,\n)\n\nprint(\"‚úÖ Runner created.\")","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# Test 1: Tell the agent about a gift (first conversation)\n# The callback will automatically save this to memory when the turn completes\nawait run_session(\n    auto_runner,\n    \"I gifted a new toy to my nephew on his 1st birthday!\",\n    \"auto-save-test\",\n)\n\n# Test 2: Ask about the gift in a NEW session (second conversation)\n# The agent should retrieve the memory using preload_memory and answer correctly\nawait run_session(\n    auto_runner,\n    \"What did I gift my nephew?\",\n    \"auto-save-test-2\",  # Different session ID - proves memory works across sessions!\n)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"markdown","source":"**What just happened:**\n\n1. **First conversation:** Mentioned gift to nephew\n   - Callback automatically saved to memory ‚úÖ\n2. **Second conversation (new session):** Asked about the gift  \n   - `preload_memory` automatically retrieved the memory ‚úÖ\n   - Agent answered correctly ‚úÖ\n\n**Zero manual memory calls!** This is automated memory management in action.","metadata":{}},{"cell_type":"markdown","source":"### 6.5 How often should you save Sessions to Memory?\n\n**Options:**\n\n| Timing | Implementation | Best For |\n|--------|----------------|----------|\n| **After every turn** | `after_agent_callback` | Real-time memory updates |\n| **End of conversation** | Manual call when session ends | Batch processing, reduce API calls |\n| **Periodic intervals** | Timer-based background job | Long-running conversations |","metadata":{}},{"cell_type":"markdown","source":"---\n## üß© Section 7: Memory Consolidation","metadata":{}},{"cell_type":"markdown","source":"### 7.1 The Limitation of Raw Storage\n\n**What we've stored so far:**\n- Every user message\n- Every agent response  \n- Every tool call\n\n**The problem:**\n```\nSession: 50 messages = 10,000 tokens\nMemory:  All 50 messages stored\nSearch:  Returns all 50 messages ‚Üí Agent must process 10,000 tokens\n```\n\nThis doesn't scale. We need **consolidation**.","metadata":{}},{"cell_type":"markdown","source":"### 7.2 What is Memory Consolidation?\n\n**Memory Consolidation** = Extracting **only important facts** while discarding conversational noise.\n\n**Before (Raw Storage):**\n\n```\nUser: \"My favorite color is BlueGreen. I also like purple. \n       Actually, I prefer BlueGreen most of the time.\"\nAgent: \"Great! I'll remember that.\"\nUser: \"Thanks!\"\nAgent: \"You're welcome!\"\n\n‚Üí Stores ALL 4 messages (redundant, verbose)\n```\n\n**After (Consolidation):**\n\n```\nExtracted Memory: \"User's favorite color: BlueGreen\"\n\n‚Üí Stores 1 concise fact\n```\n\n**Benefits:** Less storage, faster retrieval, more accurate answers.","metadata":{}},{"cell_type":"markdown","source":"<img src=\"https://storage.googleapis.com/github-repo/kaggle-5days-ai/day3/memory-consolidation.png\" width=\"1400\" alt=\"Memory consolidation\">","metadata":{}},{"cell_type":"markdown","source":"### 7.3 How Consolidation Works (Conceptual)\n\n**The pipeline:**\n\n```\n1. Raw Session Events\n   ‚Üì\n2. LLM analyzes conversation\n   ‚Üì\n3. Extracts key facts\n   ‚Üì\n4. Stores concise memories\n   ‚Üì\n5. Merges with existing memories (deduplication)\n```\n\n**Example transformation:**\n\n```\nInput:  \"I'm allergic to peanuts. I can't eat anything with nuts.\"\n\nOutput: Memory {\n  allergy: \"peanuts, tree nuts\"\n  severity: \"avoid completely\"\n}\n```\n\nNatural language ‚Üí Structured, actionable data.","metadata":{}},{"cell_type":"markdown","source":"### 7.4 Next Steps for Memory Consolidation\n\n**üí° Key Point:** Managed Memory Services handle consolidation **automatically**. \n\n**You use the same API:**\n- `add_session_to_memory()` ‚Üê Same method\n- `search_memory()` ‚Üê Same method\n\n**The difference:** What happens behind the scenes.\n- **InMemoryMemoryService:** Stores raw events\n- **VertexAiMemoryBankService:** Intelligently consolidates before storing\n\n**üìö Learn More:**\n- [Vertex AI Memory Bank: Memory Consolidation Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories) -> You'll explore this in Day 5!\n","metadata":{}},{"cell_type":"markdown","source":"---\n## üìä Summary","metadata":{}},{"cell_type":"markdown","source":"You've learned the **core mechanics** of Memory in ADK:\n\n1. **‚úÖ Adding Memory**\n   - Initialize `MemoryService` alongside `SessionService`\n   - Both services are provided to the `Runner`\n\n2. **‚úÖ Storing Information**\n   - `await memory_service.add_session_to_memory(session)`\n   - Transfers session data to long-term storage\n   - Can be automated with callbacks\n\n3. **‚úÖ Searching Memory**\n   - `await memory_service.search_memory(app_name, user_id, query)`\n   - Returns relevant memories from past conversations\n\n4. **‚úÖ Retrieving in Agents**\n   - **Reactive:** `load_memory` tool (agent decides when to use memory)\n   - **Proactive:** `preload_memory` tool (always loads memory into LLM's system instructions)\n\n5. **‚úÖ Memory Consolidation**\n   - Extracts key information from Session data\n   - Provided by managed memory services such as Vertex AI Memory Bank","metadata":{}},{"cell_type":"markdown","source":"## üéâ **Congratulations!** You've learned Memory Management in ADK!","metadata":{}},{"cell_type":"markdown","source":"**üìö Learn More:**\n- [ADK Memory Documentation](https://google.github.io/adk-docs/sessions/memory/)\n- [Vertex AI Memory Bank](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/overview)\n- [Memory Consolidation Guide](https://cloud.google.com/vertex-ai/generative-ai/docs/agent-engine/memory-bank/generate-memories)\n\n**üéØ Next Steps:**\n\nReady for Day 4? Learn how to **implement Observability and Evaluate your agents** to ensure they're working as intended in production!","metadata":{}},{"cell_type":"markdown","source":"---\n\n## Authors\n\n| Authors |\n| --- |\n| [Sampath M](https://www.linkedin.com/in/msampathkumar/) |","metadata":{}}]}