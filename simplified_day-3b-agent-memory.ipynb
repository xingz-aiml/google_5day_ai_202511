{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Management - Part 2 - Memory\n",
    "\n",
    "- ‚úÖ Initialize MemoryService and integrate with your agent\n",
    "- ‚úÖ Transfer session data to memory storage\n",
    "- ‚úÖ Search and retrieve memories\n",
    "- ‚úÖ Automate memory storage and retrieval\n",
    "- ‚úÖ Understand memory consolidation (conceptual overview)\n",
    "\n",
    "\n",
    "## Session vs Memory\n",
    "\n",
    "> **Session = Short-term memory** (single conversation)\n",
    "\n",
    "> **Memory = Long-term knowledge** (across multiple conversations)\n",
    "\n",
    "Memory provides capabilities that Sessions alone cannot:\n",
    "\n",
    "| Capability | What It Means | Example |\n",
    "|------------|---------------|---------|\n",
    "| **Cross-Conversation Recall** | Access information from any past conversation | \"What preferences has this user mentioned across all chats?\" |\n",
    "| **Intelligent Extraction** | LLM-powered consolidation extracts key facts | Stores \"allergic to peanuts\" instead of 50 raw messages |\n",
    "| **Semantic Search** | Meaning-based retrieval, not just keyword matching | Query \"preferred hue\" matches \"favorite color is blue\" |\n",
    "| **Persistent Storage** | Survives application restarts | Build knowledge that grows over time |\n",
    "\n",
    "**Example:** Imagine talking to a personal assistant:\n",
    "- üó£Ô∏è **Session**: They remember what you said 10 minutes ago in THIS conversation\n",
    "- üß† **Memory**: They remember your preferences from conversations LAST WEEK\n",
    "\n",
    "\n",
    "Note: \n",
    "- This notebook uses `InMemoryMemoryService` for learning - it performs keyword matching and doesn't persist data. \n",
    "- For production applications, use **Vertex AI Memory Bank** (covered in Day 5), which provides LLM-powered consolidation and semantic search with persistent cloud storage.\n",
    "\n",
    "\n",
    "## SessionService & MemoryService & & Agent & Runner\n",
    "\n",
    "- session_service: per-conversation working state (messages, scratch, cached tool results)\n",
    "- memory_service: curated cross-conversation memories (selective, policy-gated)\n",
    "- agent: policy/brain; given state, emits next action(s) (respond, ask, tool call, plan)\n",
    "- runner: orchestrator; enforces budgets/policy, executes actions/tools, updates session, proposes/commits memory\n",
    "\n",
    "**one specific example**\n",
    "- Runner: \"Here's user input + context. What do you want to do?\"\n",
    "- Agent:  \"Call tool X with args Y\"\n",
    "- Runner: [executes tool X, gets result]\n",
    "- Runner: \"Tool returned Z. Now what?\"\n",
    "- Agent:  \"Respond to user with this message\"\n",
    "- Runner: [sends response, updates session/memory]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 1. Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T02:00:04.563022Z",
     "iopub.status.busy": "2026-01-02T02:00:04.562725Z",
     "iopub.status.idle": "2026-01-02T02:00:04.619492Z",
     "shell.execute_reply": "2026-01-02T02:00:04.618742Z",
     "shell.execute_reply.started": "2026-01-02T02:00:04.562997Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Gemini API key setup complete.\n",
      "‚úÖ ADK components imported successfully.\n",
      "‚úÖ Specified retry_config.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "try:\n",
    "    load_dotenv()\n",
    "    print(\"‚úÖ Gemini API key setup complete.\")\n",
    "except Exception as e:\n",
    "    print(\n",
    "        f\"üîë Authentication Error: Please make sure you have added 'GOOGLE_API_KEY' to your Kaggle secrets. Details: {e}\"\n",
    "    )\n",
    "\n",
    "from google.adk.agents import LlmAgent\n",
    "from google.adk.models.google_llm import Gemini\n",
    "from google.adk.runners import Runner\n",
    "from google.adk.sessions import InMemorySessionService\n",
    "from google.adk.memory import InMemoryMemoryService\n",
    "from google.adk.tools import load_memory, preload_memory\n",
    "from google.genai import types\n",
    "\n",
    "print(\"‚úÖ ADK components imported successfully.\")\n",
    "\n",
    "\n",
    "retry_config = types.HttpRetryOptions(\n",
    "    attempts=5,  # Maximum retry attempts\n",
    "    exp_base=7,  # Delay multiplier\n",
    "    initial_delay=1,\n",
    "    http_status_codes=[429, 500, 503, 504],  # Retry on these HTTP errors\n",
    ")\n",
    "print(\"‚úÖ Specified retry_config.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T02:00:26.129129Z",
     "iopub.status.busy": "2026-01-02T02:00:26.128659Z",
     "iopub.status.idle": "2026-01-02T02:00:26.136832Z",
     "shell.execute_reply": "2026-01-02T02:00:26.135999Z",
     "shell.execute_reply.started": "2026-01-02T02:00:26.129107Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Helper functions defined.\n"
     ]
    }
   ],
   "source": [
    "async def run_session(\n",
    "    runner_instance: Runner,\n",
    "    session_service: InMemorySessionService, \n",
    "    user_id: str,\n",
    "    user_queries: list[str] | str, \n",
    "    session_id: str = \"default\"\n",
    "):\n",
    "    \"\"\"Helper function to run queries in a session and display responses.\"\"\"\n",
    "    print(f\"\\n### Session: {session_id}\")\n",
    "\n",
    "    app_name = runner_instance.app_name\n",
    "\n",
    "    # Create or retrieve session\n",
    "    try:\n",
    "        session = await session_service.create_session(\n",
    "            app_name=app_name,  user_id=user_id, session_id=session_id\n",
    "        )\n",
    "    except:\n",
    "        session = await session_service.get_session(\n",
    "            app_name=app_name, user_id=user_id, session_id=session_id\n",
    "        )\n",
    "\n",
    "    # Convert single query to list\n",
    "    if isinstance(user_queries, str):\n",
    "        user_queries = [user_queries]\n",
    "\n",
    "    # Process each query\n",
    "    for query in user_queries:\n",
    "        print(f\"\\nUser > {query}\")\n",
    "        query_content = types.Content(role=\"user\", parts=[types.Part(text=query)])\n",
    "\n",
    "        # Stream agent response\n",
    "        async for event in runner_instance.run_async(\n",
    "            user_id=user_id, session_id=session.id, new_message=query_content\n",
    "        ):\n",
    "            if event.is_final_response() and event.content and event.content.parts:\n",
    "                text = event.content.parts[0].text\n",
    "                if text and text != \"None\":\n",
    "                    print(f\"Model: > {text}\")\n",
    "\n",
    "\n",
    "print(\"‚úÖ Helper functions defined.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# Xing's Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T02:04:39.725781Z",
     "iopub.status.busy": "2026-01-02T02:04:39.724786Z",
     "iopub.status.idle": "2026-01-02T02:04:39.732733Z",
     "shell.execute_reply": "2026-01-02T02:04:39.731944Z",
     "shell.execute_reply.started": "2026-01-02T02:04:39.725750Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Tool - callback created.\n",
      "‚úÖ Core components created.\n"
     ]
    }
   ],
   "source": [
    "# tools \n",
    "# ------------------------------------------------------------------\n",
    "async def auto_save_to_memory(callback_context):\n",
    "    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
    "    await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
    "        callback_context._invocation_context.session\n",
    "    )\n",
    "\n",
    "\n",
    "print(\"‚úÖ Tool - callback created.\")\n",
    "\n",
    "\n",
    "# key components\n",
    "# ------------------------------------------------------------------\n",
    "USER_ID = 'p_li_mom'\n",
    "APP_NAME = 'p_li_with_auto_load_save_memory'\n",
    "\n",
    "# 1. Session Service\n",
    "session_service = InMemorySessionService()  # Handles conversations\n",
    "\n",
    "# 2. Memory Service\n",
    "memory_service = InMemoryMemoryService()\n",
    "\n",
    "# 3. Agent \n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words. You may need to use the load_memory tool first to check for relevant context about the user.\",\n",
    "    tools = [load_memory], # or preload_memory (load_ is reactive up to agent's judgement while preload is proactive)\n",
    "    after_agent_callback=auto_save_to_memory,  # Optional, and adding this allows for auto memory saving after each call to agent\n",
    "    \n",
    ")\n",
    "\n",
    "# 4. Runner\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service, \n",
    ")\n",
    "\n",
    "print(\"‚úÖ Core components created.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T02:05:53.660749Z",
     "iopub.status.busy": "2026-01-02T02:05:53.660194Z",
     "iopub.status.idle": "2026-01-02T02:05:55.159418Z",
     "shell.execute_reply": "2026-01-02T02:05:55.158623Z",
     "shell.execute_reply.started": "2026-01-02T02:05:53.660721Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: session_ONE\n",
      "\n",
      "User > my dog's name is pumpkin li. it is a labradoodle. it is 4\n",
      "Model: > Thanks for sharing! Pumpkin Li sounds like a lovely labradoodle. Is there anything I can help you with regarding Pumpkin Li?\n",
      "\n",
      "### Session: session_TWO\n",
      "\n",
      "User > tell me more about my dog\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning: there are non-text parts in the response: ['function_call'], returning concatenated text result from text parts. Check the full candidates.content.parts accessor to get the full model response.\n",
      "/Users/xing.zhang/anaconda3/envs/google-adk/lib/python3.11/site-packages/google/adk/flows/llm_flows/base_llm_flow.py:449: UserWarning: [EXPERIMENTAL] feature FeatureName.PROGRESSIVE_SSE_STREAMING is enabled.\n",
      "  async for event in agen:\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: > Pumpkin Li is a labradoodle and is 4 years old.\n"
     ]
    }
   ],
   "source": [
    "common_kargs = {'runner_instance': runner,\n",
    "                'session_service': session_service,\n",
    "                'user_id': USER_ID,\n",
    "                }\n",
    "\n",
    "await run_session(\n",
    "    user_queries=\"my dog's name is pumpkin li. it is a labradoodle. it is 4\",\n",
    "    session_id = \"session_ONE\",\n",
    "    **common_kargs\n",
    ")\n",
    "\n",
    "# manually load session to memory\n",
    "# session = await session_service.get_session(app_name = APP_NAME, user_id = USER_ID, session_id = \"p_li_session_1\")\n",
    "# await memory_service.add_session_to_memory(session)\n",
    "\n",
    "await run_session(\n",
    "    user_queries = \"tell me more about my dog\",\n",
    "    session_id = \"session_TWO\", # !!Different from one\n",
    "    **common_kargs\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2026-01-02T02:06:01.794175Z",
     "iopub.status.busy": "2026-01-02T02:06:01.793861Z",
     "iopub.status.idle": "2026-01-02T02:06:01.800807Z",
     "shell.execute_reply": "2026-01-02T02:06:01.799631Z",
     "shell.execute_reply.started": "2026-01-02T02:06:01.794153Z"
    },
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Search Results:\n",
      "  Found 2 relevant memories\n",
      "\n",
      "  [user]: my dog's name is pumpkin li. it is a labradoodle. it is 4...\n",
      "  [user]: tell me more about my dog...\n"
     ]
    }
   ],
   "source": [
    "# more detailed api usage to save and search memory\n",
    "search_response = await memory_service.search_memory(\n",
    "    app_name=APP_NAME, user_id=USER_ID, query=\"dog\"\n",
    ")\n",
    "\n",
    "print(\"üîç Search Results:\")\n",
    "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
    "print()\n",
    "\n",
    "for memory in search_response.memories:\n",
    "    if memory.content and memory.content.parts:\n",
    "        text = memory.content.parts[0].text[:80]\n",
    "        print(f\"  [{memory.author}]: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2. <span style=\"color:blue\">Manual</span> Memory Workflow\n",
    "\n",
    "Three steps to integrate Memory into your Agents:\n",
    "\n",
    "1. **Initialize** ‚Üí Create a `MemoryService` and provide it to your agent via the `Runner`\n",
    "2. **<span style=\"color:blue\">Ingest (MANUAL)</span>** ‚Üí Transfer session data to memory using `add_session_to_memory()`\n",
    "3. **Retrieve** -> add `load_memory` or `preload_memory` to your agent. \n",
    "    - for manual retrival, use `memory_service.search_memory()`\n",
    "\n",
    "**`load_memory` (Reactive)**\n",
    "- Pros: Efficieny (saves token) by letting agent decide when to search memory\n",
    "- Cons: Agent might forget to search\n",
    "\n",
    "**`preload_memory` (Proactive)**\n",
    "- Pros: guaranteed context by automatically search before every turn, making memory always available to the agent\n",
    "- Cons: less efficient - searches even when not needed\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialize MemoryService + Add `load_memory` to Agent for Retrival\n",
    "\n",
    "‚ÄºÔ∏è Adding `memory_service` to the `Runner` makes memory *available* to agent. To use it, explicitly \n",
    "\n",
    "1. **Ingest data** using `add_session_to_memory()` \n",
    "2. **Enable retrieval** by giving your agent memory tools (`load_memory` or `preload_memory`)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define constants used throughout the notebook\n",
    "APP_NAME = \"MemoryDemoApp\"\n",
    "USER_ID = \"demo_user\"\n",
    "\n",
    "# initialize memory service \n",
    "memory_service = (\n",
    "    InMemoryMemoryService()\n",
    ")  # ADK's built-in Memory Service for development and testing\n",
    "\n",
    "# Create Session Service\n",
    "session_service = InMemorySessionService()  # Handles conversations\n",
    "\n",
    "# Create agent\n",
    "user_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"MemoryDemoAgent\",\n",
    "    instruction=\"Answer user questions in simple words. Use load_memory tool if you need to recall past conversations.\",\n",
    "    tools=[\n",
    "        preload_memory # use load_memory might fail to retrieve if agent decides to skip\n",
    "    ],  \n",
    ")\n",
    "\n",
    "# Create runner with BOTH services\n",
    "runner = Runner(\n",
    "    agent=user_agent,\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,\n",
    "    memory_service=memory_service,  # Memory service is now available!\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 2.2 (After running session) Ingest Session Data into Memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: conversation-01\n",
      "\n",
      "User > My dog's name is pumpkin li. she is the best.\n",
      "Model: > That's a great name for a dog! Pumpkin Li sounds like a very special pup. Is there anything I can help you with regarding Pumpkin Li today?\n",
      "\n",
      "üìù Session contains:\n",
      "  user: My dog's name is pumpkin li. she is the best....\n",
      "  model: That's a great name for a dog! Pumpkin Li sounds like a very...\n"
     ]
    }
   ],
   "source": [
    "# User tells agent about their favorite color\n",
    "common_kargs = {'runner_instance': runner,\n",
    "                'session_service': session_service,\n",
    "                'user_id': USER_ID,\n",
    "                }\n",
    "                \n",
    "await run_session(\n",
    "    **common_kargs,\n",
    "    user_queries=\"My dog's name is pumpkin li. she is the best.\",\n",
    "    session_id=\"conversation-01\",  \n",
    ")\n",
    "\n",
    "# verify the conversation was captured in the session. You should see the session events containing both the user's prompt and the model's response.\n",
    "session = await session_service.get_session(\n",
    "    app_name=APP_NAME, user_id=USER_ID, session_id=\"conversation-01\"\n",
    ")\n",
    "\n",
    "# see what's in the session\n",
    "print(\"\\nüìù Session contains:\")\n",
    "for event in session.events:\n",
    "    text = (\n",
    "        event.content.parts[0].text[:60]\n",
    "        if event.content and event.content.parts\n",
    "        else \"(empty)\"\n",
    "    )\n",
    "    print(f\"  {event.content.role}: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "call `add_session_to_memory()` and pass the session object. This ingests the conversation into the memory store, making it available for future searches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: conversation-02\n",
      "\n",
      "User > describe my dog\n",
      "Model: > You told me your dog's name is Pumpkin Li. You also mentioned that she is the best!\n"
     ]
    }
   ],
   "source": [
    "# ingest to memory\n",
    "await memory_service.add_session_to_memory(session)\n",
    "\n",
    "# check if retrive from memory\n",
    "await run_session(**common_kargs, user_queries=\"describe my dog\", session_id = \"conversation-02\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manual Memory Search\n",
    "\n",
    "`search_memory()` method takes a text query and returns a `SearchMemoryResponse` with matching memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üîç Search Results:\n",
      "  Found 2 relevant memories\n",
      "\n",
      "  [user]: My dog's name is pumpkin li. she is the best....\n",
      "  [MemoryDemoAgent]: That's a great name for a dog! Pumpkin Li sounds like a very special pup. Is the...\n"
     ]
    }
   ],
   "source": [
    "# alternative retrival: explicitly through memory_service\n",
    "search_response = await memory_service.search_memory(\n",
    "    app_name=APP_NAME, user_id=USER_ID, query=\"What's my dogs name\"\n",
    ")\n",
    "\n",
    "print(\"üîç Search Results:\")\n",
    "print(f\"  Found {len(search_response.memories)} relevant memories\")\n",
    "print()\n",
    "\n",
    "for memory in search_response.memories:\n",
    "    if memory.content and memory.content.parts:\n",
    "        text = memory.content.parts[0].text[:80]\n",
    "        print(f\"  [{memory.author}]: {text}...\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "# 3. Automatic Memory Workflow\n",
    "Previous: **manually** called `add_session_to_memory()` to transfer data to long-term storage. \n",
    "\n",
    "Now: use callbacks to automate\n",
    "\n",
    "### Callbacks\n",
    "\n",
    "Callbacks are **Python functions** you define and attach to agents - ADK automatically calls them at specific stages, acting like checkpoints during the agent's execution flow.\n",
    "\n",
    "\n",
    "**Available callback types:**\n",
    "\n",
    "- `before_agent_callback` ‚Üí Runs before agent starts processing a request\n",
    "- `after_agent_callback` ‚Üí Runs after agent completes its turn  \n",
    "- `before_tool_callback` / `after_tool_callback` ‚Üí Around tool invocations\n",
    "- `before_model_callback` / `after_model_callback` ‚Üí Around LLM calls\n",
    "- `on_model_error_callback` ‚Üí When errors occur\n",
    "\n",
    "**Common use cases:**\n",
    "\n",
    "- Logging and observability (track what the agent does)\n",
    "- Automatic data persistence (like saving to memory)\n",
    "- Custom validation or filtering\n",
    "- Performance monitoring\n",
    "\n",
    "### Automatic Memory Storage with Callbacks\n",
    "\n",
    "For automatic memory storage, use `after_agent_callback`\n",
    "\n",
    "How:\n",
    "\n",
    "- `callback_context`:  ADK automatically passes it to callback functions. It provides access to the Memory Service and other runtime components.\n",
    "-  with callback_context, the function can access then calls `memory_service.add_session_to_memory()` to persist the conversation automatically."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "trusted": true
   },
   "outputs": [],
   "source": [
    "async def auto_save_to_memory(callback_context):\n",
    "    \"\"\"Automatically save session to memory after each agent turn.\"\"\"\n",
    "    await callback_context._invocation_context.memory_service.add_session_to_memory(\n",
    "        callback_context._invocation_context.session\n",
    "    )\n",
    "\n",
    "auto_memory_agent = LlmAgent(\n",
    "    model=Gemini(model=\"gemini-2.5-flash-lite\", retry_options=retry_config),\n",
    "    name=\"AutoMemoryAgent\",\n",
    "    instruction=\"Answer user questions.\",\n",
    "    tools=[preload_memory],\n",
    "    after_agent_callback=auto_save_to_memory,  # Saves after each turn!\n",
    ")\n",
    "\n",
    "auto_runner = Runner(\n",
    "    agent=auto_memory_agent,  # Use the agent with callback + preload_memory\n",
    "    app_name=APP_NAME,\n",
    "    session_service=session_service,  # Same services from the previous section\n",
    "    memory_service=memory_service,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "trusted": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "### Session: auto-save-test\n",
      "\n",
      "User > I gifted a new toy to my nephew on his 1st birthday!\n",
      "Model: > That's wonderful! A 1st birthday is such a special milestone. I hope your nephew enjoys his new toy!\n",
      "\n",
      "### Session: auto-save-test-2\n",
      "\n",
      "User > What did I gift my nephew?\n",
      "Model: > You gifted your nephew a new toy for his 1st birthday.\n"
     ]
    }
   ],
   "source": [
    "# run to test if auto memory\n",
    "common_kargs = {\"runner_instance\": auto_runner,\n",
    "               \"session_service\": session_service,\n",
    "               \"user_id\":USER_ID}\n",
    "\n",
    "await run_session(\n",
    "    **common_kargs,\n",
    "    user_queries=\"I gifted a new toy to my nephew on his 1st birthday!\",\n",
    "    session_id=\"auto-save-test\",\n",
    ")\n",
    "\n",
    "await run_session(\n",
    "    **common_kargs,\n",
    "    user_queries= \"What did I gift my nephew?\",\n",
    "    session_id=\"auto-save-test-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How often should you save Sessions to Memory?\n",
    "\n",
    "**Options:**\n",
    "\n",
    "| Timing | Implementation | Best For |\n",
    "|--------|----------------|----------|\n",
    "| **After every turn** | `after_agent_callback` | Real-time memory updates |\n",
    "| **End of conversation** | Manual call when session ends | Batch processing, reduce API calls |\n",
    "| **Periodic intervals** | Timer-based background job | Long-running conversations |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Memory Consolidation (notes only)\n",
    "- Extracts key information from Session data\n",
    "- Provided by managed memory services such as Vertex AI Memory Bank\n",
    "\n",
    "**Problem**\n",
    "\n",
    "Storing every message doesn't scale - a 50-message session means 10,000 tokens the agent must process on every search. We need **consolidation**.\n",
    "\n",
    "**Solution**\n",
    "\n",
    "extracting important facts, discarding conversational noise.\n",
    "\n",
    "| Before | After |\n",
    "|--------|-------|\n",
    "| 4 messages: \"My favorite color is BlueGreen...\" / \"Great!\" / \"Thanks!\" / \"You're welcome!\" | 1 fact: \"Favorite color: BlueGreen\" |\n",
    "\n",
    "Less storage, faster retrieval, more accurate answers.\n",
    "\n",
    "**How**\n",
    "\n",
    "Raw session ‚Üí LLM extracts key facts ‚Üí stores concise memories ‚Üí merges with existing (deduplication)\n",
    "\n",
    "e.g.\n",
    "- Input: \"I'm allergic to peanuts. I can't eat anything with nuts.\"\n",
    "- Output: `{ allergy: \"peanuts, tree nuts\", severity: \"avoid completely\" }`\n",
    "\n",
    "**Next Steps**\n",
    "\n",
    "Managed services (like VertexAiMemoryBankService) handle consolidation automatically‚Äîsame API, smarter storage."
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "none",
   "dataSources": [],
   "dockerImageVersionId": 31192,
   "isGpuEnabled": false,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "google-adk",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
